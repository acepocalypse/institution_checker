Metadata-Version: 2.4
Name: institution-checker
Version: 0.1.0
Summary: Searches public web sources and uses an LLM to verify institutional affiliations.
Author: Institution Checker Maintainers
License: Proprietary
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: aiohttp
Requires-Dist: beautifulsoup4
Requires-Dist: httpx
Requires-Dist: pandas
Requires-Dist: pyppeteer
Provides-Extra: dev
Requires-Dist: ruff; extra == "dev"
Requires-Dist: pytest; extra == "dev"

# Institution Checker

Python package for verifying whether people have connections to a target institution using web search heuristics and an LLM.

## Installation

Recommended for development (editable):

```powershell
pip install -e .
```

You can also create a normal install with `pip install .` if you prefer a non-editable install.

## Output

The tool generates CSV files with the following columns:

### Output Columns

| Column | Description |
|--------|-------------|
| `name` | The person's name being checked |
| `institution` | The target institution (configured in `config.py`) |
| `verdict` | `connected`, `not_connected`, or `uncertain` — the overall decision |
| `relationship_type` | Connection classification: `Alumni`, `Attended`, `Executive`, `Faculty`, `Postdoc`, `Staff`, `Visiting`, `Other`, or `None` |
| `relationship_timeframe` | `current`, `past`, or `unknown` — whether the affiliation is ongoing |
| `verification_detail` | Quoted evidence that proves (or rejects) the connection |
| `summary` | One-sentence summary describing the decision and context |
| `primary_source` | Best supporting URL (prefers official or authoritative sources) |
| `confidence` | `high`, `medium`, or `low` — confidence level in the decision |
| `verification_status` | `verified` when evidence is strong, otherwise `needs_review` |
| `temporal_context` | Dates/years or temporal notes extracted from the evidence |
| `connected` | Legacy boolean (`Y`/`N`) derived from `verdict` for backward compatibility |
| `connection_type` | Legacy alias mirroring `relationship_type` (deprecated) |
| `connection_detail` | Legacy alias mirroring `verification_detail` (deprecated) |
| `current_or_past` | Legacy alias mirroring `relationship_timeframe` (deprecated) |
| `supporting_url` | Legacy alias mirroring `primary_source` (deprecated) |
| `temporal_evidence` | Legacy alias mirroring `temporal_context` (deprecated) |

#### Relationship Type Categories

- **Alumni**: Graduated from the institution (undergraduate, graduate, or professional degree)
- **Attended**: Studied at the institution but did not complete a degree, or the degree is unclear
- **Executive**: Administrator, president, dean, director, or other leadership position
- **Faculty**: Professor, instructor, lecturer, or teaching position
- **Postdoc**: Postdoctoral researcher or fellow
- **Staff**: Non-teaching employee (researcher, technician, support staff)
- **Visiting**: Visiting professor/scholar with a temporary appointment
- **Other**: Official connection but none of the above categories fit
- **None**: No verified connection (used when `verdict` = `not_connected`)

### Output Files

The tool creates the following files in the `data/` directory:

- **`results.csv`**: Final results for all processed names
- **`results_partial.csv`**: Incrementally updated during batch processing (useful for monitoring progress or recovering from interruptions)

### Example Output

```csv
name,institution,verdict,relationship_type,relationship_timeframe,verification_detail,summary,primary_source,confidence,verification_status,temporal_context
Jane Doe,Purdue University,connected,Faculty,current,"She is currently a Professor of Computer Science at Purdue University.","Confirmed faculty listing in present tense.",https://www.cs.purdue.edu/people/faculty/janedoe,high,verified,"Listed as active faculty 2025"
John Smith,Purdue University,not_connected,None,unknown,"Search results do not confirm an earned degree or employment with Purdue University.","No verified institutional relationship discovered.",,low,needs_review,unknown
Bob Johnson,Purdue University,connected,Alumni,past,"He earned a PhD in Electrical Engineering from Purdue in 2018.","Alumni record confirms earned PhD in 2018.",https://engineering.purdue.edu/ECE/Alumni/Distinguished/johnson,high,verified,"PhD completed 2018"
Mary Williams,Purdue University,connected,Executive,past,"She served as Dean of the College of Engineering from 2015 to 2022.","Former dean with service ending in 2022.",https://www.purdue.edu/newsroom/releases/2015/Q2/williams-named-dean.html,high,verified,"Dean 2015-2022"
```

### Understanding Results

**Verdict**
- `connected`: Strong evidence confirms a past or present institutional relationship
- `not_connected`: No qualifying connection found in the evidence
- `uncertain`: Evidence is inconclusive — manual review recommended

**Relationship timeframe**
- `current`: Person is actively affiliated now (present tense language, current directories)
- `past`: Person previously held the affiliation (past tense, end dates, "former" language)
- `unknown`: Evidence confirms the connection but lacks precise timing cues

**Confidence Levels**
- `high`: Strong, clear evidence from authoritative sources (e.g., official faculty pages)
- `medium`: Good evidence but with some ambiguity
- `low`: Weak or unclear evidence, or no connection found

**Legacy columns**

The CSV still includes the older fields (`connected`, `connection_type`, `connection_detail`, `current_or_past`, `supporting_url`, `temporal_evidence`) for backward compatibility. They mirror the new schema and will be deprecated in a future release.

## Configuration

Before running the tool, you need to configure the LLM API key. You can do this in two ways:

### Option 1: Environment Variable (recommended for command-line usage)

```powershell
$env:LLM_API_KEY = "your-api-key-here"
```

### Option 2: Programmatic Configuration (recommended for notebook usage)

In your notebook or script, call the `set_api_key` function:

```python
from institution_checker import set_api_key

set_api_key("your-api-key-here")
```

This is particularly useful when working in notebooks where setting environment variables may be inconvenient.

The application will raise an error if the API key is not configured through either method.

## Command-line usage

Run the CLI entry point:

```powershell
institution-checker --input=data/input_names.csv
```

Or run as a module:

```powershell
python -m institution_checker --input=data/input_names.csv
```

For compatibility with older workflows you can still call the script directly:

```powershell
python main.py --input=data/input_names.csv
```

### Command-line Options

- `--input=<path>`: Path to input CSV file (default: `data/input_names.csv`)
  - Must contain a `name` column with person names to check
- `--batch-size=<number>`: Number of names to process in parallel (default: 8, max: 50)
  - Larger batches are faster but use more API quota
- `--batch-delay=<seconds>`: Delay between batches to prevent rate limiting (default: 2.5)
- `--basic` or `--basic-search`: Use only basic search (faster but less thorough)
  - By default, the tool uses enhanced search with intelligent fallback
- `--debug`: Enable detailed debug output for troubleshooting

### Examples

```powershell
# Process with custom batch size
institution-checker --input=data/my_names.csv --batch-size=5

# Use basic search for faster processing
institution-checker --input=data/names.csv --basic-search

# Debug mode with smaller batches
institution-checker --input=data/test.csv --batch-size=2 --debug

# Custom batch delay for API rate limiting
institution-checker --input=data/names.csv --batch-delay=5.0
```

## Notebook usage

This repository includes `quick_runner_notebook.ipynb` — a minimal notebook to run the pipeline interactively. Below are three practical ways to use the library from a notebook located in any directory.

1) Editable install (recommended during development)

	- From PowerShell in the project root:

	```powershell
	pip install -e .
	```

	- In a notebook cell you can ensure the kernel environment has the editable install:

	```python
	# In a Jupyter cell
	%pip install -e "C:\\Users\\setiawa\\Documents\\institution_checker"
	from institution_checker import run_pipeline, resolve_names, INSTITUTION
	```

	Editable install makes local code changes immediately importable.

2) Add `src` to sys.path at runtime (no install required)

	- Useful for quick one-off runs if you don't want to install the package. Add a small cell at the top of your notebook:

	```python
	import sys
	from pathlib import Path

	repo_root = Path(r"C:\\Users\\setiawa\\Documents\\institution_checker")
	src_path = repo_root / "src"
	if str(src_path) not in sys.path:
		 sys.path.insert(0, str(src_path))

	from institution_checker import run_pipeline, resolve_names, INSTITUTION
	```

	- This makes `institution_checker` importable without installing.

3) Regular pip install (for stable environments)

	- Install normally into the environment used by your notebook:

	```powershell
	pip install .
	```

Async function usage in notebooks

- Many functions in this project are async (for example `run_pipeline`). In Jupyter you can usually `await` at top-level in a cell:

```python
names = ["Jane Doe"]
results = await run_pipeline(names, batch_size=1)
```

- If your kernel does not support top-level `await`, wrap calls:

```python
import asyncio

async def _call():
	 return await run_pipeline(names, batch_size=1)

results = asyncio.run(_call())
```

- If you get "This event loop is already running" when using `asyncio.run`, use the notebook-friendly option (prefer `await`) or install `nest_asyncio` and apply it before `asyncio.run`:

```python
import nest_asyncio
nest_asyncio.apply()
```

Running the Quick Runner notebook

- Open `quick_runner_notebook.ipynb` in JupyterLab / Jupyter Notebook.
- Top cells contain imports and configuration (INPUT_MODE, NAME_LIST, etc.).
- There is a "Reload" cell that reloads the package if you made local edits — run it after changing source files.
- The notebook includes sections to:
  - Configure inputs
  - Resolve names
  - Reload module (for dev)
  - Run the pipeline (async)
  - Diagnose LLM output
  - Re-run failed names and export results

Troubleshooting

- ImportError: If importing `institution_checker` fails, verify either the editable install succeeded or the `src` path is added to `sys.path`. Inside a notebook, run `import sys; print(sys.executable)` and `%pip list` to confirm the environment.
- Kernel environment mismatch: Use `%pip install -e` inside the notebook to ensure the package installs into the notebook kernel's Python.
- Event loop errors: prefer top-level `await` in Jupyter. If you must use `asyncio.run` and the kernel already has a running loop, use `nest_asyncio`.
- Module caching: after editing source, reload with:

```python
import importlib, institution_checker as ic
importlib.reload(ic)
```

If you want, the notebook can add `src` to `sys.path` automatically on load — see `quick_runner_notebook.ipynb` for an example cell.

## Performance and Processing

### Search Strategy

The tool uses an intelligent cascading search approach:

1. **Basic Search First**: Tries a simpler, faster search initially
2. **Enhanced Search Escalation**: Upgrades to comprehensive multi-query search if:
   - Fewer than 8 results found, OR
   - Fewer than 3 high-quality results (relevance score ≥ 10)
3. **Fallback Protection**: Always attempts basic search before failing

### Processing Pipeline

1. **Phase 1 - Search**: All names in a batch search in parallel
2. **Phase 2 - LLM Analysis**: Results analyzed in parallel (max 4 concurrent API calls)
3. **Error Handling**: Failed records are automatically retried with smaller batch sizes
4. **Resource Management**: Automatic cleanup between batches to prevent performance degradation

### Timeouts and Retries

- **Per-name timeout**: 240 seconds (4 minutes) maximum
- **Per-LLM-call timeout**: 30 seconds for fast failure
- **Automatic retries**: Up to 2 attempts for failed LLM calls
- **Batch retry**: Failed records are automatically retried at the end with smaller batches

### Monitoring Progress

Watch the console output for real-time progress:
```
[PIPELINE] Starting: 10 name(s) in 2 batch(es) using enhanced search
[BATCH] Processing 5 names: Name1, Name2, Name3, Name4, Name5
[PROGRESS] Starting search for: Name1
[PROGRESS] Search completed for Name1 in 2.3s, found 15 results
[PROGRESS] Starting LLM analysis for: Name1
[OK] Name1: connected (current, high) - Professor of Computer Science
```

Check `data/results_partial.csv` during long runs to see intermediate results.

## Input Format

Your input CSV file must contain a `name` column:

```csv
name
Jane Doe
John Smith
Alice Johnson
```

Additional columns are allowed but will be ignored. The tool processes each name in the `name` column.

### Encoding and Special Characters

The tool **automatically fixes encoding errors** (mojibake) in names using the `ftfy` library. This handles common issues like:

- `France A. Câˆšâ‰¥rdova` → automatically fixed to `France A. Córdova`
- `FranÃ§ois` → automatically fixed to `François`
- `JosÃ© GarcÃ­a` → automatically fixed to `José García`

**Best practices:**
- Save CSV files with UTF-8 encoding
- Names with accents/diacritics are fully supported
- No manual cleaning needed - automatic repair happens on load
- See `ENCODING_FIX.md` for technical details

The tool also handles name variations intelligently:
- Middle name vs. initial: "John S. Smith" matches "John Samuel Smith"
- Diacritics: "Córdova" matches "Cordova" during search
- Name order: "Smith, John" matches "John Smith"

## Evaluation and Validation

The output columns are designed for automated evaluation:

- Compare `connected` against ground truth to measure precision/recall
- Compare `current_or_past` for temporal accuracy
- Use `confidence` to analyze model certainty
- Review `temporal_context` and `verification_detail` for error analysis

If you need to add evaluation columns (e.g., `all correct`, `connection correct`, `type correct`, `temporal correct`), you can merge the output with your ground truth data using pandas or Excel.

## Code Quality & Refactoring

### Duplicate Code Analysis

A comprehensive analysis has been completed identifying opportunities to remove duplicate code (~150-200 lines, ~5% of codebase) without affecting functionality.

**Documentation available in the project root:**
- `ANALYSIS_SUMMARY.md` - Executive overview and recommendations
- `DUPLICATE_CODE_ANALYSIS.md` - Detailed analysis with code examples
- `QUICK_REFERENCE.md` - Exact duplicate locations with line numbers
- `IMPLEMENTATION_GUIDE.md` - Step-by-step refactoring instructions
- `VISUAL_MAP.md` - Architecture and dependency diagrams

**Key findings:**
- 3 high-priority duplicates (error building, utility functions)
- 2 medium-priority consolidation opportunities (text normalization, institution helpers)
- Phase 1 refactoring: 10 minutes → removes 25 LOC
- Full refactoring: 45-60 minutes → removes 175 LOC
- Risk level: Low (all changes isolated, full rollback plan included)

Start with `ANALYSIS_SUMMARY.md` for a quick decision on whether to refactor.

## Contributing

Please file issues or pull requests for problems or improvements.

---

If you'd like, I can insert a convenience cell at the top of `quick_runner_notebook.ipynb` that automatically ensures `src` is on `sys.path` and prints the resolved import path — say the word "insert" and I'll add it.
